{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. サーバーレス推論エンドポイント デプロイ\n",
    "\n",
    "## 概要\n",
    "1. カスタム推論コード（inference.py）の作成\n",
    "2. 推論用コンテナイメージの準備\n",
    "3. SageMakerモデルの登録\n",
    "4. サーバーレスエンドポイントの作成\n",
    "5. 動作確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import tarfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sm_client = boto3.client('sagemaker')\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "SAGEMAKER_BUCKET = sess.default_bucket()\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "REGION = 'us-east-1'\n",
    "ACCOUNT_ID = boto3.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "# モデルS3パス（03_training.ipynbで出力された値を設定）\n",
    "MODEL_S3_URI = f's3://{SAGEMAKER_BUCKET}/yolo-pose/models/XXXXXXXX-XXXXXX/model.tar.gz'  # TODO: 実際のパスに置換\n",
    "\n",
    "# エンドポイント名\n",
    "ENDPOINT_NAME = 'facteye-meter-keypoint'\n",
    "MODEL_NAME = 'facteye-meter-keypoint-model'\n",
    "ENDPOINT_CONFIG_NAME = 'facteye-meter-keypoint-config'\n",
    "\n",
    "print(f'Account: {ACCOUNT_ID}')\n",
    "print(f'Region: {REGION}')\n",
    "print(f'Role: {ROLE}')\n",
    "print(f'Model: {MODEL_S3_URI}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. カスタム推論コード (inference.py) の作成\n",
    "\n",
    "SageMakerの推論コンテナで実行されるカスタムコード。\n",
    "- `model_fn`: モデルのロード\n",
    "- `input_fn`: リクエストのデシリアライズ\n",
    "- `predict_fn`: 推論実行\n",
    "- `output_fn`: レスポンスのシリアライズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFERENCE_CODE = '''\n",
    "import json\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"モデルをロードする\"\"\"\n",
    "    onnx_path = os.path.join(model_dir, \"best.onnx\")\n",
    "    config_path = os.path.join(model_dir, \"model_config.json\")\n",
    "    \n",
    "    # ONNXランタイムセッション\n",
    "    session = ort.InferenceSession(\n",
    "        onnx_path,\n",
    "        providers=[\"CPUExecutionProvider\"]\n",
    "    )\n",
    "    \n",
    "    # モデル設定\n",
    "    with open(config_path) as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    return {\"session\": session, \"config\": config}\n",
    "\n",
    "\n",
    "def input_fn(request_body, content_type):\n",
    "    \"\"\"リクエストをデシリアライズする\"\"\"\n",
    "    if content_type in (\"image/jpeg\", \"image/png\"):\n",
    "        image = Image.open(io.BytesIO(request_body)).convert(\"RGB\")\n",
    "        return {\"image\": image}\n",
    "    elif content_type == \"application/json\":\n",
    "        data = json.loads(request_body)\n",
    "        # Base64エンコードされた画像の場合\n",
    "        import base64\n",
    "        image_bytes = base64.b64decode(data[\"image\"])\n",
    "        image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "        return {\"image\": image, \"metadata\": data.get(\"metadata\", {})}\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported content type: {content_type}\")\n",
    "\n",
    "\n",
    "def preprocess(image, input_size=640):\n",
    "    \"\"\"画像を前処理する（リサイズ + 正規化）\"\"\"\n",
    "    orig_w, orig_h = image.size\n",
    "    \n",
    "    # アスペクト比を保持してリサイズ（letterbox）\n",
    "    scale = min(input_size / orig_w, input_size / orig_h)\n",
    "    new_w = int(orig_w * scale)\n",
    "    new_h = int(orig_h * scale)\n",
    "    \n",
    "    image_resized = image.resize((new_w, new_h), Image.BILINEAR)\n",
    "    \n",
    "    # パディング（グレーで埋める）\n",
    "    canvas = Image.new(\"RGB\", (input_size, input_size), (114, 114, 114))\n",
    "    pad_x = (input_size - new_w) // 2\n",
    "    pad_y = (input_size - new_h) // 2\n",
    "    canvas.paste(image_resized, (pad_x, pad_y))\n",
    "    \n",
    "    # numpy配列に変換 + 正規化\n",
    "    img_array = np.array(canvas, dtype=np.float32) / 255.0\n",
    "    # HWC -> CHW\n",
    "    img_array = np.transpose(img_array, (2, 0, 1))\n",
    "    # バッチ次元追加\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    return img_array, {\n",
    "        \"orig_w\": orig_w,\n",
    "        \"orig_h\": orig_h,\n",
    "        \"scale\": scale,\n",
    "        \"pad_x\": pad_x,\n",
    "        \"pad_y\": pad_y\n",
    "    }\n",
    "\n",
    "\n",
    "def postprocess(output, preprocess_info, config, conf_threshold=0.5):\n",
    "    \"\"\"推論結果を後処理する\n",
    "    \n",
    "    YOLOv8-poseの出力形式:\n",
    "    [batch, num_detections, 5 + num_keypoints*3]\n",
    "    5 = cx, cy, w, h, confidence\n",
    "    num_keypoints * 3 = (x, y, visibility) per keypoint\n",
    "    \"\"\"\n",
    "    predictions = output[0]  # shape: [1, num_detections, 5+kp*3]\n",
    "    if len(predictions.shape) == 3:\n",
    "        predictions = predictions[0]  # remove batch dim\n",
    "    \n",
    "    # 転置が必要な場合（YOLOv8の出力は [features, detections] の場合がある）\n",
    "    if predictions.shape[0] < predictions.shape[1]:\n",
    "        predictions = predictions.T\n",
    "    \n",
    "    num_keypoints = config.get(\"num_keypoints\", 4)\n",
    "    keypoint_labels = config.get(\"keypoint_labels\", \n",
    "        [\"needle_tip\", \"needle_center\", \"scale_min\", \"scale_max\"])\n",
    "    \n",
    "    scale = preprocess_info[\"scale\"]\n",
    "    pad_x = preprocess_info[\"pad_x\"]\n",
    "    pad_y = preprocess_info[\"pad_y\"]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for det in predictions:\n",
    "        # bbox: cx, cy, w, h\n",
    "        cx, cy, w, h = det[0], det[1], det[2], det[3]\n",
    "        confidence = det[4]\n",
    "        \n",
    "        if confidence < conf_threshold:\n",
    "            continue\n",
    "        \n",
    "        # パディングとスケールを元に戻す\n",
    "        cx = (cx - pad_x) / scale\n",
    "        cy = (cy - pad_y) / scale\n",
    "        w = w / scale\n",
    "        h = h / scale\n",
    "        \n",
    "        # キーポイント抽出\n",
    "        keypoints = {}\n",
    "        for i in range(num_keypoints):\n",
    "            kp_offset = 5 + i * 3\n",
    "            kp_x = (det[kp_offset] - pad_x) / scale\n",
    "            kp_y = (det[kp_offset + 1] - pad_y) / scale\n",
    "            kp_conf = det[kp_offset + 2]\n",
    "            \n",
    "            keypoints[keypoint_labels[i]] = {\n",
    "                \"x\": float(kp_x),\n",
    "                \"y\": float(kp_y),\n",
    "                \"confidence\": float(kp_conf)\n",
    "            }\n",
    "        \n",
    "        results.append({\n",
    "            \"bbox\": {\n",
    "                \"cx\": float(cx),\n",
    "                \"cy\": float(cy),\n",
    "                \"width\": float(w),\n",
    "                \"height\": float(h)\n",
    "            },\n",
    "            \"confidence\": float(confidence),\n",
    "            \"keypoints\": keypoints\n",
    "        })\n",
    "    \n",
    "    # confidence降順でソート\n",
    "    results.sort(key=lambda x: x[\"confidence\"], reverse=True)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def predict_fn(input_data, model):\n",
    "    \"\"\"推論を実行する\"\"\"\n",
    "    session = model[\"session\"]\n",
    "    config = model[\"config\"]\n",
    "    image = input_data[\"image\"]\n",
    "    \n",
    "    input_size = config.get(\"input_size\", 640)\n",
    "    \n",
    "    # 前処理\n",
    "    img_array, preprocess_info = preprocess(image, input_size)\n",
    "    \n",
    "    # 推論\n",
    "    input_name = session.get_inputs()[0].name\n",
    "    output = session.run(None, {input_name: img_array})\n",
    "    \n",
    "    # 後処理\n",
    "    detections = postprocess(output, preprocess_info, config)\n",
    "    \n",
    "    return {\n",
    "        \"detections\": detections,\n",
    "        \"image_size\": {\n",
    "            \"width\": preprocess_info[\"orig_w\"],\n",
    "            \"height\": preprocess_info[\"orig_h\"]\n",
    "        },\n",
    "        \"metadata\": input_data.get(\"metadata\", {})\n",
    "    }\n",
    "\n",
    "\n",
    "def output_fn(prediction, accept):\n",
    "    \"\"\"レスポンスをシリアライズする\"\"\"\n",
    "    if accept == \"application/json\":\n",
    "        return json.dumps(prediction), accept\n",
    "    else:\n",
    "        return json.dumps(prediction), \"application/json\"\n",
    "'''\n",
    "\n",
    "# 推論コードをファイルに保存\n",
    "inference_dir = Path('/tmp/inference_code')\n",
    "inference_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "(inference_dir / 'inference.py').write_text(INFERENCE_CODE.strip())\n",
    "print('inference.py 作成完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. requirements.txt の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REQUIREMENTS = \"\"\"onnxruntime==1.17.1\n",
    "numpy>=1.24.0\n",
    "Pillow>=10.0.0\n",
    "\"\"\"\n",
    "\n",
    "(inference_dir / 'requirements.txt').write_text(REQUIREMENTS.strip())\n",
    "print('requirements.txt 作成完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 推論コード付きモデルアーティファクトの作成\n",
    "\n",
    "SageMakerでは `model.tar.gz` に推論コードを含めることができる。\n",
    "\n",
    "```\n",
    "model.tar.gz/\n",
    "├── best.onnx\n",
    "├── model_config.json\n",
    "└── code/\n",
    "    ├── inference.py\n",
    "    └── requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 既存のmodel.tar.gzをダウンロード\n",
    "model_s3_parts = MODEL_S3_URI.replace('s3://', '').split('/', 1)\n",
    "model_bucket = model_s3_parts[0]\n",
    "model_key = model_s3_parts[1]\n",
    "\n",
    "local_model_tar = Path('/tmp/model_original.tar.gz')\n",
    "s3.download_file(model_bucket, model_key, str(local_model_tar))\n",
    "print(f'モデルダウンロード完了: {local_model_tar}')\n",
    "\n",
    "# 展開\n",
    "extract_dir = Path('/tmp/model_extracted')\n",
    "if extract_dir.exists():\n",
    "    shutil.rmtree(extract_dir)\n",
    "extract_dir.mkdir(parents=True)\n",
    "\n",
    "with tarfile.open(str(local_model_tar), 'r:gz') as tar:\n",
    "    tar.extractall(str(extract_dir))\n",
    "\n",
    "print(f'展開ファイル: {list(extract_dir.rglob(\"*\"))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論コードをcodeディレクトリに配置\n",
    "code_dir = extract_dir / 'code'\n",
    "code_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shutil.copy2(inference_dir / 'inference.py', code_dir / 'inference.py')\n",
    "shutil.copy2(inference_dir / 'requirements.txt', code_dir / 'requirements.txt')\n",
    "\n",
    "# 新しいmodel.tar.gzを作成\n",
    "new_model_tar = Path('/tmp/model_with_code.tar.gz')\n",
    "with tarfile.open(str(new_model_tar), 'w:gz') as tar:\n",
    "    for item in extract_dir.rglob('*'):\n",
    "        if item.is_file():\n",
    "            arcname = str(item.relative_to(extract_dir))\n",
    "            tar.add(str(item), arcname=arcname)\n",
    "\n",
    "print(f'新model.tar.gz: {new_model_tar}')\n",
    "print(f'サイズ: {new_model_tar.stat().st_size / 1024 / 1024:.1f} MB')\n",
    "\n",
    "# 内容確認\n",
    "with tarfile.open(str(new_model_tar), 'r:gz') as tar:\n",
    "    print('\\n含まれるファイル:')\n",
    "    for member in tar.getmembers():\n",
    "        print(f'  {member.name} ({member.size} bytes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3にアップロード\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "deploy_model_key = f'yolo-pose/deploy/{timestamp}/model.tar.gz'\n",
    "\n",
    "s3.upload_file(\n",
    "    str(new_model_tar),\n",
    "    SAGEMAKER_BUCKET,\n",
    "    deploy_model_key\n",
    ")\n",
    "\n",
    "DEPLOY_MODEL_S3_URI = f's3://{SAGEMAKER_BUCKET}/{deploy_model_key}'\n",
    "print(f'デプロイ用モデルアップロード完了: {DEPLOY_MODEL_S3_URI}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SageMaker モデル登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "# PyTorchの推論コンテナイメージを使用（ONNX Runtime含む）\n",
    "framework_version = '2.1'\n",
    "py_version = 'py310'\n",
    "\n",
    "image_uri = retrieve(\n",
    "    framework='pytorch',\n",
    "    region=REGION,\n",
    "    version=framework_version,\n",
    "    py_version=py_version,\n",
    "    instance_type='ml.m5.large',  # サーバーレスでもイメージ取得に必要\n",
    "    image_scope='inference'\n",
    ")\n",
    "\n",
    "print(f'コンテナイメージ: {image_uri}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 既存のモデル・エンドポイントを削除（再デプロイ時）\n",
    "for name, delete_fn, describe_fn in [\n",
    "    (ENDPOINT_NAME, sm_client.delete_endpoint, sm_client.describe_endpoint),\n",
    "    (ENDPOINT_CONFIG_NAME, sm_client.delete_endpoint_config, sm_client.describe_endpoint_config),\n",
    "    (MODEL_NAME, sm_client.delete_model, sm_client.describe_model),\n",
    "]:\n",
    "    try:\n",
    "        describe_fn(**{list(describe_fn.__code__.co_varnames)[1]: name})\n",
    "        delete_fn(**{list(delete_fn.__code__.co_varnames)[1]: name})\n",
    "        print(f'削除: {name}')\n",
    "    except sm_client.exceptions.ClientError:\n",
    "        pass  # 存在しない場合は無視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SageMakerモデル作成\n",
    "sm_client.create_model(\n",
    "    ModelName=MODEL_NAME,\n",
    "    PrimaryContainer={\n",
    "        'Image': image_uri,\n",
    "        'ModelDataUrl': DEPLOY_MODEL_S3_URI,\n",
    "        'Environment': {\n",
    "            'SAGEMAKER_PROGRAM': 'inference.py',\n",
    "            'SAGEMAKER_SUBMIT_DIRECTORY': DEPLOY_MODEL_S3_URI,\n",
    "        }\n",
    "    },\n",
    "    ExecutionRoleArn=ROLE,\n",
    "    Tags=[\n",
    "        {'Key': 'Project', 'Value': 'facteye'},\n",
    "        {'Key': 'Component', 'Value': 'meter-keypoint'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f'モデル作成完了: {MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. サーバーレスエンドポイント設定\n",
    "\n",
    "### サーバーレス推論の設定パラメータ\n",
    "| パラメータ | 値 | 説明 |\n",
    "|-----------|-----|------|\n",
    "| MemorySizeInMB | 4096 | メモリサイズ（ONNXモデル + 画像処理に十分な量） |\n",
    "| MaxConcurrency | 5 | 最大同時実行数 |\n",
    "\n",
    "**コールドスタート**: 初回呼び出しは30-60秒程度のレイテンシが発生。許容する方針。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サーバーレスエンドポイント設定\n",
    "MEMORY_SIZE_MB = 4096  # 4GB\n",
    "MAX_CONCURRENCY = 5\n",
    "\n",
    "sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            'VariantName': 'AllTraffic',\n",
    "            'ModelName': MODEL_NAME,\n",
    "            'ServerlessConfig': {\n",
    "                'MemorySizeInMB': MEMORY_SIZE_MB,\n",
    "                'MaxConcurrency': MAX_CONCURRENCY,\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    Tags=[\n",
    "        {'Key': 'Project', 'Value': 'facteye'},\n",
    "        {'Key': 'Component', 'Value': 'meter-keypoint'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f'エンドポイント設定作成完了: {ENDPOINT_CONFIG_NAME}')\n",
    "print(f'  メモリ: {MEMORY_SIZE_MB} MB')\n",
    "print(f'  最大同時実行数: {MAX_CONCURRENCY}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンドポイント作成\n",
    "sm_client.create_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_NAME,\n",
    "    Tags=[\n",
    "        {'Key': 'Project', 'Value': 'facteye'},\n",
    "        {'Key': 'Component', 'Value': 'meter-keypoint'},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f'エンドポイント作成開始: {ENDPOINT_NAME}')\n",
    "print('InService になるまで待機します...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エンドポイントのステータスを待機\n",
    "import time\n",
    "\n",
    "while True:\n",
    "    response = sm_client.describe_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "    status = response['EndpointStatus']\n",
    "    print(f'Status: {status}')\n",
    "    \n",
    "    if status == 'InService':\n",
    "        print('\\nエンドポイントが利用可能になりました！')\n",
    "        break\n",
    "    elif status == 'Failed':\n",
    "        print(f'\\nエンドポイント作成に失敗しました')\n",
    "        print(f'理由: {response.get(\"FailureReason\", \"unknown\")}')\n",
    "        break\n",
    "    \n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 動作確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# テスト画像をS3から取得\n",
    "TEST_IMAGE_KEY = 'images/'  # TODO: 実際のテスト画像パスに置換\n",
    "\n",
    "# S3から画像を1枚取得してテスト\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "test_key = None\n",
    "for page in paginator.paginate(Bucket='facteye-images-20251114', Prefix='images/', MaxKeys=1):\n",
    "    for obj in page.get('Contents', []):\n",
    "        if obj['Key'].endswith('.jpg'):\n",
    "            test_key = obj['Key']\n",
    "            break\n",
    "    if test_key:\n",
    "        break\n",
    "\n",
    "if test_key:\n",
    "    print(f'テスト画像: {test_key}')\n",
    "    response = s3.get_object(Bucket='facteye-images-20251114', Key=test_key)\n",
    "    image_bytes = response['Body'].read()\n",
    "    print(f'画像サイズ: {len(image_bytes)} bytes')\n",
    "else:\n",
    "    print('テスト画像が見つかりません')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論実行\n",
    "if test_key and image_bytes:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = runtime.invoke_endpoint(\n",
    "        EndpointName=ENDPOINT_NAME,\n",
    "        ContentType='image/jpeg',\n",
    "        Accept='application/json',\n",
    "        Body=image_bytes\n",
    "    )\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    result = json.loads(response['Body'].read().decode('utf-8'))\n",
    "    \n",
    "    print(f'推論時間: {elapsed:.2f}秒')\n",
    "    print(f'検出数: {len(result.get(\"detections\", []))}')\n",
    "    print(f'\\n結果:')\n",
    "    print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. エンドポイント情報の保存\n",
    "\n",
    "Lambda関数から呼び出す際に必要な情報を保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_info = {\n",
    "    'endpoint_name': ENDPOINT_NAME,\n",
    "    'model_name': MODEL_NAME,\n",
    "    'endpoint_config_name': ENDPOINT_CONFIG_NAME,\n",
    "    'model_s3_uri': DEPLOY_MODEL_S3_URI,\n",
    "    'region': REGION,\n",
    "    'memory_size_mb': MEMORY_SIZE_MB,\n",
    "    'max_concurrency': MAX_CONCURRENCY,\n",
    "    'deployed_at': datetime.now().isoformat(),\n",
    "    'container_image': image_uri,\n",
    "    'invoke_example': {\n",
    "        'python': f\"\"\"import boto3\\nruntime = boto3.client('sagemaker-runtime')\\nresponse = runtime.invoke_endpoint(\\n    EndpointName='{ENDPOINT_NAME}',\\n    ContentType='image/jpeg',\\n    Accept='application/json',\\n    Body=image_bytes\\n)\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# ローカルに保存\n",
    "info_path = Path('/tmp/endpoint_info.json')\n",
    "info_path.write_text(json.dumps(endpoint_info, indent=2))\n",
    "\n",
    "# S3にも保存\n",
    "s3.put_object(\n",
    "    Bucket=SAGEMAKER_BUCKET,\n",
    "    Key='yolo-pose/endpoint/endpoint_info.json',\n",
    "    Body=json.dumps(endpoint_info, indent=2).encode('utf-8')\n",
    ")\n",
    "\n",
    "print('エンドポイント情報:')\n",
    "print(json.dumps(endpoint_info, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次のステップ\n",
    "\n",
    "**05_inference_test.ipynb** で以下を実行:\n",
    "- 複数画像での推論テスト\n",
    "- キーポイントから角度・値を算出するロジックの検証\n",
    "- Bedrockとの精度比較\n",
    "\n",
    "### Lambda統合時の情報\n",
    "- エンドポイント名: `facteye-meter-keypoint`\n",
    "- ContentType: `image/jpeg`\n",
    "- Accept: `application/json`\n",
    "- レスポンス形式: `{\"detections\": [{\"keypoints\": {...}, \"confidence\": ...}]}`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}