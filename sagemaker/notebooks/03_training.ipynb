{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. YOLOv8n-pose モデル学習\n",
    "\n",
    "## 概要\n",
    "1. YOLOv8n-poseの事前学習済みモデルをベースにファインチューニング\n",
    "2. 学習済みモデルをONNX形式にエクスポート\n",
    "3. モデルアーティファクトをS3に保存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依存パッケージのインストール\n",
    "!pip install ultralytics onnx onnxruntime --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import sagemaker\n",
    "from ultralytics import YOLO\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "SAGEMAKER_BUCKET = sess.default_bucket()\n",
    "\n",
    "# パス設定\n",
    "DATASET_DIR = Path('/tmp/yolo_dataset')\n",
    "DATASET_YAML = DATASET_DIR / 'dataset.yaml'\n",
    "OUTPUT_DIR = Path('/tmp/yolo_output')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'Dataset: {DATASET_DIR}')\n",
    "print(f'Output: {OUTPUT_DIR}')\n",
    "print(f'S3 Bucket: {SAGEMAKER_BUCKET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. データセットの確認\n",
    "\n",
    "02_annotation_to_yolo.ipynbで作成したデータセットを確認する。\n",
    "存在しない場合はS3からダウンロードする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# ローカルにデータセットがない場合はS3からダウンロード\n",
    "if not DATASET_YAML.exists():\n",
    "    print('ローカルにデータセットが見つかりません。S3からダウンロードします...')\n",
    "    S3_DATASET_URI = f's3://{SAGEMAKER_BUCKET}/yolo-pose/dataset'\n",
    "    cmd = f'aws s3 sync {S3_DATASET_URI} {DATASET_DIR} --quiet'\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f'ダウンロードエラー: {result.stderr}')\n",
    "    else:\n",
    "        print('ダウンロード完了')\n",
    "\n",
    "# 確認\n",
    "print(f'\\ndataset.yaml 存在: {DATASET_YAML.exists()}')\n",
    "if DATASET_YAML.exists():\n",
    "    print(DATASET_YAML.read_text())\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_dir = DATASET_DIR / 'images' / split\n",
    "    if img_dir.exists():\n",
    "        count = len(list(img_dir.glob('*.*')))\n",
    "        print(f'{split}: {count} images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. YOLOv8n-pose モデル学習\n",
    "\n",
    "### ハイパーパラメータ\n",
    "| パラメータ | 値 | 説明 |\n",
    "|-----------|-----|------|\n",
    "| model | yolov8n-pose.pt | 軽量版poseモデル |\n",
    "| epochs | 100 | エポック数 |\n",
    "| imgsz | 640 | 入力画像サイズ |\n",
    "| batch | 16 | バッチサイズ |\n",
    "| patience | 20 | Early stopping patience |\n",
    "| lr0 | 0.01 | 初期学習率 |\n",
    "| lrf | 0.01 | 最終学習率係数 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータ\n",
    "EPOCHS = 100\n",
    "IMAGE_SIZE = 640\n",
    "BATCH_SIZE = 16\n",
    "PATIENCE = 20\n",
    "LR0 = 0.01\n",
    "LRF = 0.01\n",
    "\n",
    "# モデルロード（事前学習済み）\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "\n",
    "print(f'モデル: yolov8n-pose')\n",
    "print(f'パラメータ数: {sum(p.numel() for p in model.model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習実行\n",
    "results = model.train(\n",
    "    data=str(DATASET_YAML),\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    patience=PATIENCE,\n",
    "    lr0=LR0,\n",
    "    lrf=LRF,\n",
    "    project=str(OUTPUT_DIR),\n",
    "    name='meter_keypoint',\n",
    "    exist_ok=True,\n",
    "    # データ拡張\n",
    "    hsv_h=0.015,\n",
    "    hsv_s=0.7,\n",
    "    hsv_v=0.4,\n",
    "    degrees=15.0,     # 回転（メーターの傾き対応）\n",
    "    translate=0.1,\n",
    "    scale=0.3,\n",
    "    flipud=0.0,       # 上下反転は無効（メーターは向き固定）\n",
    "    fliplr=0.0,       # 左右反転も無効\n",
    "    mosaic=0.5,\n",
    ")\n",
    "\n",
    "print('\\n学習完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 学習結果の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果ディレクトリ\n",
    "train_dir = OUTPUT_DIR / 'meter_keypoint'\n",
    "\n",
    "# best.pt の存在確認\n",
    "best_pt = train_dir / 'weights' / 'best.pt'\n",
    "last_pt = train_dir / 'weights' / 'last.pt'\n",
    "\n",
    "print(f'best.pt 存在: {best_pt.exists()}')\n",
    "if best_pt.exists():\n",
    "    print(f'best.pt サイズ: {best_pt.stat().st_size / 1024 / 1024:.1f} MB')\n",
    "\n",
    "print(f'last.pt 存在: {last_pt.exists()}')\n",
    "\n",
    "# results.csv の確認\n",
    "results_csv = train_dir / 'results.csv'\n",
    "if results_csv.exists():\n",
    "    import csv\n",
    "    with open(results_csv) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        rows = list(reader)\n",
    "        if rows:\n",
    "            last_row = rows[-1]\n",
    "            print(f'\\n最終エポック結果:')\n",
    "            for key, val in last_row.items():\n",
    "                key = key.strip()\n",
    "                if key:\n",
    "                    print(f'  {key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線の画像を表示\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "results_img = train_dir / 'results.png'\n",
    "if results_img.exists():\n",
    "    display(IPImage(filename=str(results_img)))\n",
    "else:\n",
    "    print('results.png が見つかりません')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. テストデータでの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best.pt をロードして評価\n",
    "best_model = YOLO(str(best_pt))\n",
    "\n",
    "# testデータで評価\n",
    "test_results = best_model.val(\n",
    "    data=str(DATASET_YAML),\n",
    "    split='test',\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    batch=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(f'\\nテスト結果:')\n",
    "print(f'  mAP50: {test_results.box.map50:.4f}')\n",
    "print(f'  mAP50-95: {test_results.box.map:.4f}')\n",
    "if hasattr(test_results, 'pose'):\n",
    "    print(f'  Pose mAP50: {test_results.pose.map50:.4f}')\n",
    "    print(f'  Pose mAP50-95: {test_results.pose.map:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ONNX形式にエクスポート\n",
    "\n",
    "サーバーレス推論エンドポイントではONNXランタイムを使用するため、best.ptをONNXに変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX エクスポート\n",
    "onnx_path = best_model.export(\n",
    "    format='onnx',\n",
    "    imgsz=IMAGE_SIZE,\n",
    "    simplify=True,\n",
    "    opset=17\n",
    ")\n",
    "\n",
    "print(f'\\nONNXモデル: {onnx_path}')\n",
    "print(f'サイズ: {Path(onnx_path).stat().st_size / 1024 / 1024:.1f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX モデルの動作確認\n",
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(str(onnx_path))\n",
    "\n",
    "# 入出力の確認\n",
    "print('入力:')\n",
    "for inp in ort_session.get_inputs():\n",
    "    print(f'  {inp.name}: {inp.shape} ({inp.type})')\n",
    "\n",
    "print('\\n出力:')\n",
    "for out in ort_session.get_outputs():\n",
    "    print(f'  {out.name}: {out.shape} ({out.type})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. モデルアーティファクトをS3に保存\n",
    "\n",
    "SageMakerサーバーレスエンドポイント用に `model.tar.gz` を作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "# model.tar.gz の構造:\n",
    "# model.tar.gz/\n",
    "# ├── best.onnx         # ONNXモデル\n",
    "# └── model_config.json  # モデル設定（キーポイント定義等）\n",
    "\n",
    "model_config = {\n",
    "    'model_type': 'yolov8n-pose',\n",
    "    'input_size': IMAGE_SIZE,\n",
    "    'num_keypoints': 4,\n",
    "    'keypoint_labels': ['needle_tip', 'needle_center', 'scale_min', 'scale_max'],\n",
    "    'class_names': ['meter'],\n",
    "    'created_at': datetime.now().isoformat(),\n",
    "    'training_epochs': EPOCHS,\n",
    "    'training_batch_size': BATCH_SIZE\n",
    "}\n",
    "\n",
    "# model_config.json を保存\n",
    "config_path = OUTPUT_DIR / 'model_config.json'\n",
    "config_path.write_text(json.dumps(model_config, indent=2))\n",
    "\n",
    "# tar.gz 作成\n",
    "tarball_path = OUTPUT_DIR / 'model.tar.gz'\n",
    "with tarfile.open(str(tarball_path), 'w:gz') as tar:\n",
    "    tar.add(str(onnx_path), arcname='best.onnx')\n",
    "    tar.add(str(config_path), arcname='model_config.json')\n",
    "\n",
    "print(f'model.tar.gz: {tarball_path}')\n",
    "print(f'サイズ: {tarball_path.stat().st_size / 1024 / 1024:.1f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3にアップロード\n",
    "timestamp = datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "model_s3_key = f'yolo-pose/models/{timestamp}/model.tar.gz'\n",
    "\n",
    "s3.upload_file(\n",
    "    str(tarball_path),\n",
    "    SAGEMAKER_BUCKET,\n",
    "    model_s3_key\n",
    ")\n",
    "\n",
    "MODEL_S3_URI = f's3://{SAGEMAKER_BUCKET}/{model_s3_key}'\n",
    "print(f'モデルアップロード完了: {MODEL_S3_URI}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果（ログ、画像）もS3に保存\n",
    "results_s3_prefix = f'yolo-pose/training-results/{timestamp}'\n",
    "cmd = f'aws s3 sync {train_dir} s3://{SAGEMAKER_BUCKET}/{results_s3_prefix} --quiet'\n",
    "result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f'学習結果アップロード完了: s3://{SAGEMAKER_BUCKET}/{results_s3_prefix}')\n",
    "else:\n",
    "    print(f'エラー: {result.stderr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 学習結果サマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 60)\n",
    "print('学習結果サマリー')\n",
    "print('=' * 60)\n",
    "print(f'モデル: yolov8n-pose (fine-tuned)')\n",
    "print(f'エポック: {EPOCHS}')\n",
    "print(f'画像サイズ: {IMAGE_SIZE}x{IMAGE_SIZE}')\n",
    "print(f'ONNX モデルサイズ: {Path(onnx_path).stat().st_size / 1024 / 1024:.1f} MB')\n",
    "print(f'model.tar.gz サイズ: {tarball_path.stat().st_size / 1024 / 1024:.1f} MB')\n",
    "print(f'\\nS3 モデルパス: {MODEL_S3_URI}')\n",
    "print(f'S3 学習結果: s3://{SAGEMAKER_BUCKET}/{results_s3_prefix}')\n",
    "print('=' * 60)\n",
    "print('\\n次のステップ: 04_deploy_serverless.ipynb でサーバーレスエンドポイントをデプロイ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次のステップ\n",
    "\n",
    "**04_deploy_serverless.ipynb** で以下を実行:\n",
    "- カスタム推論コード（inference.py）の作成\n",
    "- SageMakerモデルの登録\n",
    "- サーバーレス推論エンドポイントのデプロイ\n",
    "\n",
    "### 使用する情報\n",
    "- モデルS3パス: `MODEL_S3_URI` の値をコピー"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}