{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. アノテーション変換 - Ground Truth出力 → YOLOv8-pose形式\n",
    "\n",
    "## 概要\n",
    "1. Ground Truthの出力マニフェスト（JSONL）を読み込み\n",
    "2. キーポイントデータをYOLOv8-pose形式に変換\n",
    "3. train / val / test に分割\n",
    "4. 学習用ディレクトリ構造をS3に配置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "SAGEMAKER_BUCKET = sess.default_bucket()\n",
    "SOURCE_BUCKET = 'facteye-images-20251114'\n",
    "REGION = 'us-east-1'\n",
    "\n",
    "# ローカル作業ディレクトリ\n",
    "WORK_DIR = Path('/tmp/yolo_dataset')\n",
    "WORK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# データ分割比率\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.2\n",
    "TEST_RATIO = 0.1\n",
    "\n",
    "# キーポイント定義（Ground Truthラベルとの対応）\n",
    "KEYPOINT_LABELS = ['needle_tip', 'needle_center', 'scale_min', 'scale_max']\n",
    "NUM_KEYPOINTS = len(KEYPOINT_LABELS)\n",
    "\n",
    "print(f'作業ディレクトリ: {WORK_DIR}')\n",
    "print(f'キーポイント数: {NUM_KEYPOINTS}')\n",
    "print(f'分割比率: train={TRAIN_RATIO}, val={VAL_RATIO}, test={TEST_RATIO}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ground Truth 出力マニフェスト読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground Truth ジョブ名を指定\n",
    "GT_JOB_NAME = 'facteye-meter-keypoint-XXXXXXXX-XXXXXX'  # TODO: 実際のジョブ名に置換\n",
    "\n",
    "# 出力マニフェストのS3パス\n",
    "OUTPUT_MANIFEST_KEY = f'ground-truth/output/{GT_JOB_NAME}/manifests/output/output.manifest'\n",
    "\n",
    "def load_ground_truth_manifest(bucket, key):\n",
    "    \"\"\"Ground Truthの出力マニフェスト（JSONL）を読み込む\"\"\"\n",
    "    response = s3.get_object(Bucket=bucket, Key=key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    \n",
    "    entries = []\n",
    "    for line in content.strip().split('\\n'):\n",
    "        if line.strip():\n",
    "            entries.append(json.loads(line))\n",
    "    \n",
    "    return entries\n",
    "\n",
    "manifest_entries = load_ground_truth_manifest(SAGEMAKER_BUCKET, OUTPUT_MANIFEST_KEY)\n",
    "print(f'マニフェストエントリ数: {len(manifest_entries)}')\n",
    "\n",
    "# サンプル表示\n",
    "if manifest_entries:\n",
    "    print('\\nサンプルエントリ:')\n",
    "    print(json.dumps(manifest_entries[0], indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ground Truth キーポイント形式の解析\n",
    "\n",
    "Ground Truthの `crowd-keypoint` 出力形式:\n",
    "```json\n",
    "{\n",
    "  \"source-ref\": \"s3://bucket/key\",\n",
    "  \"keypoints\": {\n",
    "    \"annotations\": [\n",
    "      {\n",
    "        \"class_id\": 0,\n",
    "        \"width\": 10,\n",
    "        \"height\": 10,\n",
    "        \"top\": 100,\n",
    "        \"left\": 200\n",
    "      }\n",
    "    ],\n",
    "    \"image_size\": [{\"width\": 640, \"height\": 480, \"depth\": 3}]\n",
    "  },\n",
    "  \"keypoints-metadata\": {\n",
    "    \"objects\": [{\"confidence\": 0.95}],\n",
    "    \"class-map\": {\"0\": \"needle_tip\", \"1\": \"needle_center\", ...},\n",
    "    \"type\": \"groundtruth/keypoint\"\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ground_truth_keypoints(entry, label_attribute='keypoints'):\n",
    "    \"\"\"Ground Truthエントリからキーポイント情報を抽出\n",
    "    \n",
    "    Returns:\n",
    "        dict: {\n",
    "            'source_ref': str,\n",
    "            'image_width': int,\n",
    "            'image_height': int,\n",
    "            'keypoints': {\n",
    "                'needle_tip': (x, y, visibility),\n",
    "                'needle_center': (x, y, visibility),\n",
    "                'scale_min': (x, y, visibility),\n",
    "                'scale_max': (x, y, visibility)\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "    source_ref = entry['source-ref']\n",
    "    annotation_data = entry.get(label_attribute, {})\n",
    "    metadata = entry.get(f'{label_attribute}-metadata', {})\n",
    "    \n",
    "    # 画像サイズ\n",
    "    image_size = annotation_data.get('image_size', [{}])[0]\n",
    "    img_w = image_size.get('width', 0)\n",
    "    img_h = image_size.get('height', 0)\n",
    "    \n",
    "    # クラスマップ (class_id -> label)\n",
    "    class_map = metadata.get('class-map', {})\n",
    "    \n",
    "    # キーポイント抽出\n",
    "    keypoints = {}\n",
    "    annotations = annotation_data.get('annotations', [])\n",
    "    \n",
    "    for ann in annotations:\n",
    "        class_id = str(ann.get('class_id', ''))\n",
    "        label = class_map.get(class_id, f'unknown_{class_id}')\n",
    "        \n",
    "        # キーポイントの中心座標を計算（left, top はバウンディングボックスの左上）\n",
    "        x = ann.get('left', 0) + ann.get('width', 0) / 2\n",
    "        y = ann.get('top', 0) + ann.get('height', 0) / 2\n",
    "        visibility = 2  # visible\n",
    "        \n",
    "        keypoints[label] = (x, y, visibility)\n",
    "    \n",
    "    return {\n",
    "        'source_ref': source_ref,\n",
    "        'image_width': img_w,\n",
    "        'image_height': img_h,\n",
    "        'keypoints': keypoints\n",
    "    }\n",
    "\n",
    "# テストパース\n",
    "if manifest_entries:\n",
    "    sample = parse_ground_truth_keypoints(manifest_entries[0])\n",
    "    print(f'Source: {sample[\"source_ref\"]}')\n",
    "    print(f'Image size: {sample[\"image_width\"]}x{sample[\"image_height\"]}')\n",
    "    for label, (x, y, v) in sample['keypoints'].items():\n",
    "        print(f'  {label}: ({x:.1f}, {y:.1f}, vis={v})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. YOLOv8-pose 形式への変換\n",
    "\n",
    "### YOLOv8-pose ラベルフォーマット\n",
    "```\n",
    "<class_id> <cx> <cy> <w> <h> <kp1_x> <kp1_y> <kp1_v> <kp2_x> <kp2_y> <kp2_v> ...\n",
    "```\n",
    "- 座標は画像サイズで正規化（0.0〜1.0）\n",
    "- `class_id`: 0（メーター）\n",
    "- `cx, cy, w, h`: バウンディングボックス（キーポイントを囲む矩形）\n",
    "- `kp_x, kp_y`: キーポイント座標（正規化）\n",
    "- `kp_v`: 可視性（0=不可視, 1=遮蔽, 2=可視）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bounding_box(keypoints_dict, img_w, img_h, padding_ratio=0.1):\n",
    "    \"\"\"キーポイントを囲むバウンディングボックスを計算（正規化座標）\n",
    "    \n",
    "    Args:\n",
    "        keypoints_dict: {label: (x, y, v)}\n",
    "        img_w: 画像幅\n",
    "        img_h: 画像高さ\n",
    "        padding_ratio: パディング（短辺に対する比率）\n",
    "    \n",
    "    Returns:\n",
    "        (cx, cy, w, h): 正規化されたバウンディングボックス\n",
    "    \"\"\"\n",
    "    xs = [kp[0] for kp in keypoints_dict.values()]\n",
    "    ys = [kp[1] for kp in keypoints_dict.values()]\n",
    "    \n",
    "    x_min, x_max = min(xs), max(xs)\n",
    "    y_min, y_max = min(ys), max(ys)\n",
    "    \n",
    "    # パディング追加\n",
    "    pad_x = (x_max - x_min) * padding_ratio\n",
    "    pad_y = (y_max - y_min) * padding_ratio\n",
    "    \n",
    "    x_min = max(0, x_min - pad_x)\n",
    "    x_max = min(img_w, x_max + pad_x)\n",
    "    y_min = max(0, y_min - pad_y)\n",
    "    y_max = min(img_h, y_max + pad_y)\n",
    "    \n",
    "    # YOLO形式（中心 + サイズ、正規化）\n",
    "    cx = ((x_min + x_max) / 2) / img_w\n",
    "    cy = ((y_min + y_max) / 2) / img_h\n",
    "    w = (x_max - x_min) / img_w\n",
    "    h = (y_max - y_min) / img_h\n",
    "    \n",
    "    return cx, cy, w, h\n",
    "\n",
    "\n",
    "def convert_to_yolo_pose(parsed_entry):\n",
    "    \"\"\"パース済みエントリをYOLOv8-pose形式のラベル文字列に変換\n",
    "    \n",
    "    Returns:\n",
    "        str: YOLO形式のラベル行\n",
    "             \"<class_id> <cx> <cy> <w> <h> <kp1_x> <kp1_y> <kp1_v> ...\"\n",
    "    \"\"\"\n",
    "    img_w = parsed_entry['image_width']\n",
    "    img_h = parsed_entry['image_height']\n",
    "    kps = parsed_entry['keypoints']\n",
    "    \n",
    "    if not kps or img_w == 0 or img_h == 0:\n",
    "        return None\n",
    "    \n",
    "    # バウンディングボックス\n",
    "    cx, cy, w, h = compute_bounding_box(kps, img_w, img_h)\n",
    "    \n",
    "    # キーポイント（定義順に並べる）\n",
    "    kp_values = []\n",
    "    for label in KEYPOINT_LABELS:\n",
    "        if label in kps:\n",
    "            x, y, v = kps[label]\n",
    "            kp_values.extend([x / img_w, y / img_h, v])\n",
    "        else:\n",
    "            # キーポイントが欠損の場合\n",
    "            kp_values.extend([0.0, 0.0, 0])\n",
    "    \n",
    "    # class_id = 0（メーター）\n",
    "    parts = [0, cx, cy, w, h] + kp_values\n",
    "    return ' '.join(f'{v:.6f}' if isinstance(v, float) else str(v) for v in parts)\n",
    "\n",
    "\n",
    "# テスト変換\n",
    "if manifest_entries:\n",
    "    sample_parsed = parse_ground_truth_keypoints(manifest_entries[0])\n",
    "    yolo_line = convert_to_yolo_pose(sample_parsed)\n",
    "    print(f'YOLO形式: {yolo_line}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 品質チェック & 不良データ除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_annotation(parsed_entry):\n",
    "    \"\"\"アノテーションの品質チェック\n",
    "    \n",
    "    除外条件:\n",
    "    - キーポイントが全て同じ座標（判別不能マーク）\n",
    "    - 必須キーポイントの欠損\n",
    "    - 画像サイズが0\n",
    "    \"\"\"\n",
    "    if parsed_entry['image_width'] == 0 or parsed_entry['image_height'] == 0:\n",
    "        return False, 'image_size_zero'\n",
    "    \n",
    "    kps = parsed_entry['keypoints']\n",
    "    \n",
    "    # 必須キーポイントの存在チェック\n",
    "    required = ['needle_tip', 'needle_center']\n",
    "    for label in required:\n",
    "        if label not in kps:\n",
    "            return False, f'missing_{label}'\n",
    "    \n",
    "    # 全て同じ座標チェック（判別不能マーク）\n",
    "    coords = [(kp[0], kp[1]) for kp in kps.values()]\n",
    "    if len(set(coords)) == 1:\n",
    "        return False, 'all_same_position'\n",
    "    \n",
    "    # needle_tip と needle_center が同じ位置のチェック\n",
    "    if 'needle_tip' in kps and 'needle_center' in kps:\n",
    "        tip = kps['needle_tip']\n",
    "        center = kps['needle_center']\n",
    "        dist = ((tip[0] - center[0])**2 + (tip[1] - center[1])**2)**0.5\n",
    "        if dist < 5:  # 5ピクセル未満は近すぎる\n",
    "            return False, 'needle_tip_center_too_close'\n",
    "    \n",
    "    return True, 'ok'\n",
    "\n",
    "\n",
    "# 全データの品質チェック\n",
    "valid_entries = []\n",
    "invalid_entries = []\n",
    "invalid_reasons = {}\n",
    "\n",
    "for entry in manifest_entries:\n",
    "    parsed = parse_ground_truth_keypoints(entry)\n",
    "    is_valid, reason = is_valid_annotation(parsed)\n",
    "    \n",
    "    if is_valid:\n",
    "        valid_entries.append((entry, parsed))\n",
    "    else:\n",
    "        invalid_entries.append((entry, reason))\n",
    "        invalid_reasons[reason] = invalid_reasons.get(reason, 0) + 1\n",
    "\n",
    "print(f'有効データ: {len(valid_entries)}')\n",
    "print(f'無効データ: {len(invalid_entries)}')\n",
    "if invalid_reasons:\n",
    "    print('\\n除外理由:')\n",
    "    for reason, count in invalid_reasons.items():\n",
    "        print(f'  {reason}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. データ分割 (train / val / test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シャッフル\n",
    "random.seed(42)\n",
    "random.shuffle(valid_entries)\n",
    "\n",
    "n = len(valid_entries)\n",
    "n_train = int(n * TRAIN_RATIO)\n",
    "n_val = int(n * VAL_RATIO)\n",
    "\n",
    "train_entries = valid_entries[:n_train]\n",
    "val_entries = valid_entries[n_train:n_train + n_val]\n",
    "test_entries = valid_entries[n_train + n_val:]\n",
    "\n",
    "print(f'Train: {len(train_entries)}')\n",
    "print(f'Val:   {len(val_entries)}')\n",
    "print(f'Test:  {len(test_entries)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. YOLOv8-pose ディレクトリ構造の作成\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── images/\n",
    "│   ├── train/\n",
    "│   ├── val/\n",
    "│   └── test/\n",
    "├── labels/\n",
    "│   ├── train/\n",
    "│   ├── val/\n",
    "│   └── test/\n",
    "└── dataset.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ディレクトリ作成\n",
    "for split in ['train', 'val', 'test']:\n",
    "    (WORK_DIR / 'images' / split).mkdir(parents=True, exist_ok=True)\n",
    "    (WORK_DIR / 'labels' / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def process_split(entries, split_name):\n",
    "    \"\"\"指定splitのデータを処理（画像DL + ラベル生成）\"\"\"\n",
    "    processed = 0\n",
    "    errors = 0\n",
    "    \n",
    "    for idx, (entry, parsed) in enumerate(entries):\n",
    "        source_ref = parsed['source_ref']\n",
    "        \n",
    "        # S3 URIをパース\n",
    "        # s3://bucket/key -> bucket, key\n",
    "        s3_parts = source_ref.replace('s3://', '').split('/', 1)\n",
    "        bucket = s3_parts[0]\n",
    "        key = s3_parts[1]\n",
    "        \n",
    "        # ファイル名（S3キーからユニークな名前を生成）\n",
    "        # images/company_id/device_id/YYYY/MM/DD/HHMMSS.jpg -> company_id_device_id_YYYYMMDD_HHMMSS.jpg\n",
    "        key_parts = key.split('/')\n",
    "        if len(key_parts) >= 7:\n",
    "            file_name = f'{key_parts[1]}_{key_parts[2]}_{key_parts[3]}{key_parts[4]}{key_parts[5]}_{key_parts[6]}'\n",
    "        else:\n",
    "            file_name = key.replace('/', '_')\n",
    "        \n",
    "        base_name = Path(file_name).stem\n",
    "        img_path = WORK_DIR / 'images' / split_name / file_name\n",
    "        label_path = WORK_DIR / 'labels' / split_name / f'{base_name}.txt'\n",
    "        \n",
    "        try:\n",
    "            # 画像ダウンロード\n",
    "            s3.download_file(bucket, key, str(img_path))\n",
    "            \n",
    "            # ラベル生成\n",
    "            yolo_line = convert_to_yolo_pose(parsed)\n",
    "            if yolo_line:\n",
    "                label_path.write_text(yolo_line + '\\n')\n",
    "                processed += 1\n",
    "            else:\n",
    "                # ラベル変換失敗 → 画像も削除\n",
    "                img_path.unlink(missing_ok=True)\n",
    "                errors += 1\n",
    "        except Exception as e:\n",
    "            errors += 1\n",
    "            if idx < 3:  # 最初の3件だけエラー表示\n",
    "                print(f'  Error [{idx}]: {e}')\n",
    "    \n",
    "    return processed, errors\n",
    "\n",
    "\n",
    "print('データ処理開始...')\n",
    "for split_name, entries in [('train', train_entries), ('val', val_entries), ('test', test_entries)]:\n",
    "    print(f'\\n{split_name}:')\n",
    "    processed, errors = process_split(entries, split_name)\n",
    "    print(f'  成功: {processed}, エラー: {errors}')\n",
    "\n",
    "print('\\n処理完了')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. dataset.yaml 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_yaml = f\"\"\"# FactEye Meter Keypoint Dataset\n",
    "# YOLOv8-pose format\n",
    "\n",
    "path: /tmp/yolo_dataset\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "\n",
    "# クラス定義\n",
    "names:\n",
    "  0: meter\n",
    "\n",
    "# キーポイント定義\n",
    "kpt_shape: [{NUM_KEYPOINTS}, 3]  # [キーポイント数, (x, y, visibility)]\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = WORK_DIR / 'dataset.yaml'\n",
    "yaml_path.write_text(dataset_yaml)\n",
    "print(f'dataset.yaml 生成完了: {yaml_path}')\n",
    "print()\n",
    "print(dataset_yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. S3にアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "S3_DATASET_PREFIX = 'yolo-pose/dataset'\n",
    "S3_DATASET_URI = f's3://{SAGEMAKER_BUCKET}/{S3_DATASET_PREFIX}'\n",
    "\n",
    "# aws s3 sync でアップロード\n",
    "cmd = f'aws s3 sync {WORK_DIR} {S3_DATASET_URI} --quiet'\n",
    "print(f'アップロード中: {cmd}')\n",
    "result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f'アップロード完了: {S3_DATASET_URI}')\n",
    "else:\n",
    "    print(f'エラー: {result.stderr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. データセット統計の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ローカルファイル数の確認\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_count = len(list((WORK_DIR / 'images' / split).glob('*.jpg')))\n",
    "    label_count = len(list((WORK_DIR / 'labels' / split).glob('*.txt')))\n",
    "    print(f'{split}: images={img_count}, labels={label_count}')\n",
    "    \n",
    "    if img_count != label_count:\n",
    "        print(f'  ⚠ 画像とラベルの数が一致しません！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルファイルのサンプル確認\n",
    "sample_labels = list((WORK_DIR / 'labels' / 'train').glob('*.txt'))[:3]\n",
    "for label_file in sample_labels:\n",
    "    print(f'\\n{label_file.name}:')\n",
    "    print(f'  {label_file.read_text().strip()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次のステップ\n",
    "\n",
    "データセットの準備が完了しました。**03_training.ipynb** でYOLOv8n-poseモデルの学習を実行します。\n",
    "\n",
    "### 使用する情報\n",
    "- データセットS3パス: `s3://<SAGEMAKER_BUCKET>/yolo-pose/dataset/`\n",
    "- ローカルパス: `/tmp/yolo_dataset/`\n",
    "- dataset.yaml: `/tmp/yolo_dataset/dataset.yaml`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}